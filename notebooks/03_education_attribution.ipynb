{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Education Effectiveness Attribution\n",
    "## Analyzing Course Impact Across All Disciplines\n",
    "\n",
    "This notebook analyzes the effectiveness of courses across:\n",
    "- STEM (Math, Science, Technology)\n",
    "- Humanities (Social Sciences, Languages, History)\n",
    "- Arts (Visual, Performing, Creative Writing)\n",
    "\n",
    "And their interdisciplinary connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from unified_attribution import CompleteUnifiedFramework\n",
    "\n",
    "print('='*70)\n",
    "print('EDUCATION EFFECTIVENESS ATTRIBUTION')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Educational Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "EDUCATION_TAXONOMY = {\n",
    "    'STEM': {\n",
    "        'Mathematics': ['Algebra', 'Calculus', 'Statistics', 'Geometry'],\n",
    "        'Science': ['Physics', 'Chemistry', 'Biology', 'Earth_Science'],\n",
    "        'Technology': ['Computer_Science', 'Engineering', 'Data_Science'],\n",
    "    },\n",
    "    'Humanities': {\n",
    "        'Social_Sciences': ['Psychology', 'Sociology', 'Economics', 'Political_Science'],\n",
    "        'Languages': ['English', 'Spanish', 'Mandarin', 'Writing'],\n",
    "        'History': ['World_History', 'US_History', 'Ancient_Civilizations'],\n",
    "    },\n",
    "    'Arts': {\n",
    "        'Visual_Arts': ['Painting', 'Sculpture', 'Photography', 'Design'],\n",
    "        'Performing_Arts': ['Music', 'Theater', 'Dance'],\n",
    "        'Creative_Writing': ['Poetry', 'Fiction', 'Non_Fiction'],\n",
    "    }\n",
    "}\n",
    "\n",
    "# Flatten course list\n",
    "all_courses = []\n",
    "for domain, categories in EDUCATION_TAXONOMY.items():\n",
    "    for category, courses in categories.items():\n",
    "        all_courses.extend(courses)\n",
    "\n",
    "print(f'Total courses: {len(all_courses)}')\n",
    "print(f'Domains: {list(EDUCATION_TAXONOMY.keys())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Student Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "n_students = 5000\n",
    "\n",
    "# Course enrollment\n",
    "student_data = pd.DataFrame()\n",
    "for course in all_courses:\n",
    "    base_rate = 0.3\n",
    "    if course in ['Algebra', 'English', 'Biology']:\n",
    "        base_rate = 0.9  # Core courses\n",
    "    student_data[course] = np.random.binomial(1, base_rate, n_students)\n",
    "\n",
    "# Generate grades with interdisciplinary effects\n",
    "grades = pd.DataFrame()\n",
    "for course in all_courses:\n",
    "    base_grade = np.random.normal(75, 15, n_students)\n",
    "    \n",
    "    # Math helps science\n",
    "    if course in ['Physics', 'Chemistry']:\n",
    "        math_boost = (student_data['Algebra'] + student_data['Calculus']) * 3\n",
    "        base_grade += math_boost\n",
    "    \n",
    "    # Writing helps everything\n",
    "    if course == 'Writing':\n",
    "        base_grade += student_data[all_courses].sum(axis=1) * 0.5\n",
    "    \n",
    "    grades[course] = np.clip(base_grade, 0, 100)\n",
    "\n",
    "# Overall GPA\n",
    "student_data['GPA'] = grades.mean(axis=1) / 25\n",
    "\n",
    "print(f'Generated {n_students} student records')\n",
    "print(f'Average GPA: {student_data[\"GPA\"].mean():.2f}')\n",
    "print(f'Courses per student: {student_data[all_courses].sum(axis=1).mean():.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Course Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create student journeys\n",
    "journeys = []\n",
    "for idx, row in student_data[all_courses].iterrows():\n",
    "    journey = [course for course in all_courses if row[course] == 1]\n",
    "    journeys.append(journey)\n",
    "\n",
    "# Run attribution\n",
    "framework = CompleteUnifiedFramework(\n",
    "    journeys=journeys,\n",
    "    data=student_data[all_courses],\n",
    "    epsilon=1.0\n",
    ")\n",
    "\n",
    "results, elapsed = framework.compute_complete_attribution()\n",
    "\n",
    "print(f'Attribution computed in {elapsed:.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Course Effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "course_attribution = results['hybrid']\n",
    "ranked_courses = sorted(course_attribution.items(), \n",
    "                       key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('TOP 10 MOST IMPACTFUL COURSES')\n",
    "print('='*70)\n",
    "for i, (course, impact) in enumerate(ranked_courses[:10], 1):\n",
    "    print(f'{i:2d}. {course:25s}: {impact:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interdisciplinary Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate correlations\n",
    "correlation_matrix = grades[all_courses].corr()\n",
    "\n",
    "# Find strong connections\n",
    "connections = []\n",
    "for i, c1 in enumerate(all_courses):\n",
    "    for j, c2 in enumerate(all_courses):\n",
    "        if i < j:\n",
    "            corr = correlation_matrix.loc[c1, c2]\n",
    "            if corr > 0.5:\n",
    "                connections.append((c1, c2, corr))\n",
    "\n",
    "connections.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('TOP 10 INTERDISCIPLINARY CONNECTIONS')\n",
    "print('='*70)\n",
    "for i, (c1, c2, corr) in enumerate(connections[:10], 1):\n",
    "    print(f'{i:2d}. {c1:20s} <-> {c2:20s}: {corr:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "fig.suptitle('Education Attribution Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Course impact\n",
    "ax = axes[0, 0]\n",
    "top_20 = pd.DataFrame(ranked_courses[:20], columns=['Course', 'Impact'])\n",
    "ax.barh(top_20['Course'], top_20['Impact'], color='steelblue')\n",
    "ax.set_xlabel('Attribution Weight')\n",
    "ax.set_title('Top 20 Most Impactful Courses')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Plot 2: Knowledge network\n",
    "ax = axes[0, 1]\n",
    "G = nx.Graph()\n",
    "for c in all_courses[:15]:\n",
    "    G.add_node(c)\n",
    "for c1, c2, corr in connections[:20]:\n",
    "    if c1 in all_courses[:15] and c2 in all_courses[:15]:\n",
    "        G.add_edge(c1, c2, weight=corr)\n",
    "\n",
    "pos = nx.spring_layout(G, k=0.5)\n",
    "nx.draw_networkx(G, pos, ax=ax, node_color='lightblue', \n",
    "                node_size=500, font_size=8, alpha=0.8)\n",
    "ax.set_title('Interdisciplinary Knowledge Network')\n",
    "ax.axis('off')\n",
    "\n",
    "# Plot 3: Domain impact\n",
    "ax = axes[1, 0]\n",
    "domain_impacts = {}\n",
    "for domain, categories in EDUCATION_TAXONOMY.items():\n",
    "    total = sum(course_attribution.get(c, 0) \n",
    "               for cat, courses in categories.items() \n",
    "               for c in courses)\n",
    "    domain_impacts[domain] = total\n",
    "\n",
    "ax.bar(domain_impacts.keys(), domain_impacts.values(), color='coral')\n",
    "ax.set_ylabel('Total Attribution')\n",
    "ax.set_title('Impact by Educational Domain')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 4: Correlation heatmap\n",
    "ax = axes[1, 1]\n",
    "sample_courses = all_courses[:10]\n",
    "sample_corr = correlation_matrix.loc[sample_courses, sample_courses]\n",
    "sns.heatmap(sample_corr, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "           ax=ax, square=True, cbar_kws={'label': 'Correlation'})\n",
    "ax.set_title('Course Correlation Matrix (Sample)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('education_attribution.png', dpi=300, bbox_inches='tight')\n",
    "print('Saved: education_attribution.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Course effectiveness report\n",
    "report = pd.DataFrame({\n",
    "    'Course': list(course_attribution.keys()),\n",
    "    'Impact': list(course_attribution.values()),\n",
    "    'Enrollment_Rate': [student_data[c].mean() for c in course_attribution.keys()],\n",
    "    'Avg_Grade': [grades[c].mean() for c in course_attribution.keys()]\n",
    "})\n",
    "report = report.sort_values('Impact', ascending=False)\n",
    "report.to_csv('course_effectiveness.csv', index=False)\n",
    "\n",
    "# Connections\n",
    "connections_df = pd.DataFrame(connections, \n",
    "                             columns=['Course1', 'Course2', 'Correlation'])\n",
    "connections_df.to_csv('interdisciplinary_connections.csv', index=False)\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('ANALYSIS COMPLETE')\n",
    "print('='*70)\n",
    "print('Saved: course_effectiveness.csv')\n",
    "print('Saved: interdisciplinary_connections.csv')\n",
    "print('Saved: education_attribution.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
